{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCMfVCzpZ2i4"
      },
      "source": [
        "Assumptions and Notes:\n",
        "* Data already has a 'Processed Text' column, to ensure similar process between the 2 notebooks - This one, for model training, and the other one for unsupervised analysis and finalization of xlsx file with the predicted classes.\n",
        "\n",
        "* In the tagged training data, labels appear in 'Themes' column, seperated by ', '.\n",
        "\n",
        "* If you wish to further test the models created, you should have an additional test.csv tagged file to upload for the 'Evaluation' section. The quality of these models is assured using cross validation on a full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHgL-AMZW62E"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN5HMkO3JiLx",
        "outputId": "8b0abfde-83fe-4eea-98ef-74621e101b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q optuna\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WKWf4UiOWKQs"
      },
      "outputs": [],
      "source": [
        "# Basic Python Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import ast  # For converting string representations of lists to actual lists\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
        "\n",
        "# Machine Learning and Text Analysis\n",
        "from copy import deepcopy\n",
        "import optuna\n",
        "import logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, classification_report, recall_score, confusion_matrix, make_scorer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from skopt import gp_minimize\n",
        "\n",
        "# Optional: Google Colab Specific Library (if using Google Colab)\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import files\n",
        "\n",
        "# Export Model:\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En_ZnLVEW9ua"
      },
      "source": [
        "# Get Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "6HVW3WOJXBWZ",
        "outputId": "74f76925-bfd0-44b7-b177-7b79d312e82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SecretKeys.py not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2dfd35b1-b275-4363-bdd5-bdde009fbad3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2dfd35b1-b275-4363-bdd5-bdde009fbad3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SecretKeys.py to SecretKeys.py\n",
            "File uploaded and module imported successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the filename\n",
        "filename = 'SecretKeys.py'\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"{filename} not found. Please upload the file.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "# Import the module if it exists\n",
        "if os.path.exists(filename):\n",
        "    from SecretKeys import *\n",
        "    print(\"File uploaded and module imported successfully.\")\n",
        "else:\n",
        "    print(f\"{filename} not found after upload attempt. Please check the file and try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7v9N8xBEXgnY"
      },
      "outputs": [],
      "source": [
        "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/documents.readonly']\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_dict(GoogleDriveCreds, scope)\n",
        "gc = gspread.authorize(credentials)\n",
        "\n",
        "# 1. Access sending list as DataFrame\n",
        "file_id = \"1BEq6zEIWtBXT0zAk2ECQt-zHCN1CQ4EpRyEqigQ01UY\"\n",
        "sh = gc.open_by_key(file_id)\n",
        "\n",
        "worksheet_name = \"Train Data\"\n",
        "tagged_data = pd.DataFrame(sh.worksheet(worksheet_name).get_all_records())\n",
        "# Keep only relevant columns and drop nulls - will affect the integrity of the automation\n",
        "tagged_data.replace(\"\", np.nan, inplace=True)\n",
        "tagged_data.dropna(how='any', inplace=True)\n",
        "tagged_data = tagged_data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "SVDpNYFY5BVT",
        "outputId": "cdd01518-22ad-426c-d046-edc991fa3c4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Source                                      Original Text  \\\n",
              "0  Undocumented  i appreciate that most of my managers are ther...   \n",
              "1  Undocumented  my manager: in this case would be my team lead...   \n",
              "2  Undocumented  my manager hands down has been the best manage...   \n",
              "3  Undocumented  my manager has always been ready, willing & ab...   \n",
              "4  Undocumented  mr. gray is always available to answer questio...   \n",
              "\n",
              "                                      Processed Text  \\\n",
              "0  appreciate manager answer question provide ass...   \n",
              "1  manager case team leader sure currently manage...   \n",
              "2  manager hand best manager year quick . approac...   \n",
              "3  manager ready willing able answer question ari...   \n",
              "4  mr. gray available answer question unsure hand...   \n",
              "\n",
              "                                            KeyWords  \\\n",
              "0  ['manager', 'provide', 'appreciate', 'question...   \n",
              "1  ['team', 'manager', 'best', 'person', 'helpful...   \n",
              "2  ['need', 'manager', 'help', 'quick', 'year', '...   \n",
              "3  ['work', 'manager', 'able', 'order', 'willing'...   \n",
              "4  ['issue', 'available', 'shipment', 'internatio...   \n",
              "\n",
              "                                    Themes  \n",
              "0                               management  \n",
              "1                               management  \n",
              "2  management, employee care and listening  \n",
              "3                               management  \n",
              "4                               management  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cf84658-9efa-43a9-90f0-f40694c3151e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Original Text</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>KeyWords</th>\n",
              "      <th>Themes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Undocumented</td>\n",
              "      <td>i appreciate that most of my managers are ther...</td>\n",
              "      <td>appreciate manager answer question provide ass...</td>\n",
              "      <td>['manager', 'provide', 'appreciate', 'question...</td>\n",
              "      <td>management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Undocumented</td>\n",
              "      <td>my manager: in this case would be my team lead...</td>\n",
              "      <td>manager case team leader sure currently manage...</td>\n",
              "      <td>['team', 'manager', 'best', 'person', 'helpful...</td>\n",
              "      <td>management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Undocumented</td>\n",
              "      <td>my manager hands down has been the best manage...</td>\n",
              "      <td>manager hand best manager year quick . approac...</td>\n",
              "      <td>['need', 'manager', 'help', 'quick', 'year', '...</td>\n",
              "      <td>management, employee care and listening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Undocumented</td>\n",
              "      <td>my manager has always been ready, willing &amp; ab...</td>\n",
              "      <td>manager ready willing able answer question ari...</td>\n",
              "      <td>['work', 'manager', 'able', 'order', 'willing'...</td>\n",
              "      <td>management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Undocumented</td>\n",
              "      <td>mr. gray is always available to answer questio...</td>\n",
              "      <td>mr. gray available answer question unsure hand...</td>\n",
              "      <td>['issue', 'available', 'shipment', 'internatio...</td>\n",
              "      <td>management</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cf84658-9efa-43a9-90f0-f40694c3151e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cf84658-9efa-43a9-90f0-f40694c3151e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cf84658-9efa-43a9-90f0-f40694c3151e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0691513-cc4e-4334-a2f4-c2b86aa72ea0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0691513-cc4e-4334-a2f4-c2b86aa72ea0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0691513-cc4e-4334-a2f4-c2b86aa72ea0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tagged_data",
              "summary": "{\n  \"name\": \"tagged_data\",\n  \"rows\": 1308,\n  \"fields\": [\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"KN-Quick\",\n          \"Undocumented\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1308,\n        \"samples\": [\n          \"I am always happy to learn and embrace more to make the business grow and be efficient and more profitable. learning more about specialised products we use and to be the specialist in that. Being given the chance to impart my knowledge to others within STAT to help improve in efficiency.\",\n          \"some training on the system would help - like excel, word etc. and better knowledge of the KN websites and tools they provide.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Processed Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1300,\n        \"samples\": [\n          \"improvefix issue\",\n          \"provide space meeting lunch rest area\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KeyWords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1232,\n        \"samples\": [\n          \"['work', 'performance', 'recognition', 'quarterly']\",\n          \"['team', 'feel', 'level', 'little', 'location']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Themes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 245,\n        \"samples\": [\n          \"social activities / events\",\n          \"work processes, communication, workload / work-life balance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tagged_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogiuO6IXhAPm"
      },
      "source": [
        "# Train Preprocess and Split (Train & Test)\n",
        "\n",
        "Binarize Columns, split data, balance train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j3SGOnCz6K54"
      },
      "outputs": [],
      "source": [
        "def _BinaryThemeColumns(tagged_data, themes_column='Themes'):\n",
        "    \"\"\"\n",
        "    This function takes a DataFrame and creates binary columns for each unique theme.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input DataFrame.\n",
        "    themes_column (str): The name of the column containing the list of themes.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with binary columns for each theme.\n",
        "    \"\"\"\n",
        "    # Create a copy of the DataFrame to avoid modifying the original one\n",
        "    df_copy = tagged_data.copy()\n",
        "\n",
        "    # Split themes by comma and strip whitespace\n",
        "    df_copy[themes_column] = df_copy[themes_column].apply(lambda x: [theme.strip() for theme in x.split(',')])\n",
        "\n",
        "    # Get all unique themes\n",
        "    unique_themes = set(theme for sublist in df_copy[themes_column] for theme in sublist)\n",
        "\n",
        "    # Create binary columns for each unique theme\n",
        "    for theme in unique_themes:\n",
        "        df_copy[theme] = df_copy[themes_column].apply(lambda x: 1 if theme in x else 0)\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "def TrainTestThemeSplit(tagged_data, themes_column = 'Themes', test_size=0.2, ratio = None, random_state=42):\n",
        "    \"\"\"\n",
        "    Binarize the themes column using _BinaryThemeColumns()\n",
        "    Split data into train and test sets for each theme, ensuring balance.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input DataFrame with binary theme columns.\n",
        "    themes_column (str): The column containing the list of themes for each row.\n",
        "    test_size (float): The proportion of the dataset to include in the test split.\n",
        "    ratio (int): The ratio of non-theme rows you want in the data, for example, 3 for 1:3.\n",
        "                  If input is None, will train the model compared to all of the elsewise tagged data.\n",
        "    random_state (int): The seed used by the random number generator.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary with training and testing sets for each theme.\n",
        "    \"\"\"\n",
        "    theme_datasets = {}\n",
        "    tagged_data_b = _BinaryThemeColumns(tagged_data, themes_column)\n",
        "    unique_themes = set(theme for sublist in tagged_data_b[themes_column] for theme in sublist)\n",
        "\n",
        "    for theme in unique_themes:\n",
        "        # Get all rows with the current theme\n",
        "        theme_df = tagged_data_b[tagged_data_b[theme] == 1].copy()\n",
        "\n",
        "        # Get all rows without the current theme\n",
        "        non_theme_df = tagged_data_b[tagged_data_b[theme] == 0].copy()\n",
        "\n",
        "        # Sample negative samples\n",
        "        if ratio:\n",
        "            non_theme_sample_size = min(len(theme_df) * ratio, len(non_theme_df))\n",
        "            non_theme_df = non_theme_df.sample(n=non_theme_sample_size, random_state=random_state)\n",
        "\n",
        "        # Split into train and test sets, ensure both positive and negative samples in both\n",
        "        if len(theme_df) > 1:\n",
        "            train_df_p, test_df_p = train_test_split(theme_df, test_size=test_size, random_state=random_state)\n",
        "        else:\n",
        "            train_df_p, test_df_p = theme_df, pd.DataFrame()\n",
        "\n",
        "        if len(non_theme_df) > 1:\n",
        "            train_df_n, test_df_n = train_test_split(non_theme_df, test_size=test_size, random_state=random_state)\n",
        "        else:\n",
        "            train_df_n, test_df_n = non_theme_df, pd.DataFrame()\n",
        "\n",
        "        train_df = pd.concat([train_df_p, train_df_n]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "        test_df = pd.concat([test_df_p, test_df_n]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "        # Store in dictionary\n",
        "        theme_datasets[theme] = {\n",
        "            'train': train_df,\n",
        "            'test': test_df,\n",
        "            'full_ds': tagged_data_b\n",
        "        }\n",
        "\n",
        "    return theme_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6HIu6FER9mZl"
      },
      "outputs": [],
      "source": [
        "theme_datasets = TrainTestThemeSplit(tagged_data, ratio = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYQ6NUyA-3J6",
        "outputId": "456caf8b-6201-4d68-be6c-21968ef72d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "innovation:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "stability:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "hr:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "company culture:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "overall engaged/satisfied:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "fairness / equality / inclusion:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "work processes:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "challenging work:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "cross-functional collaboration:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "within team collaboration:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "recognition:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "flexibility:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "salary / compensation:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "workload / work-life balance:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "sick / vacation days:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "social activities / events:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "systems:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "benefits:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "training:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "management:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "performance management:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "communication:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "office environment:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "customer service:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "company:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "growth / career development:  Train Size= 1045 | Test Size= 263 | DS Size= 1308\n",
            "employee care and listening:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "work process:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n",
            "professionalism:  Train Size= 1046 | Test Size= 262 | DS Size= 1308\n"
          ]
        }
      ],
      "source": [
        "for theme in theme_datasets:\n",
        "  print(f'{theme}:', ' Train Size=', len(theme_datasets[theme]['train']),\n",
        "        '| Test Size=', len(theme_datasets[theme]['test']), '| DS Size=',len(theme_datasets[theme]['full_ds']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TP8Ll2VEzz"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kw7wvc1SE_8"
      },
      "source": [
        "## Regular Training Flow\n",
        "\n",
        "Each model will output a probabilities per class prediction. Then, the following process takes place:\n",
        "\n",
        "Normalize Predictions -> Find Optimal Tresholds per label -> Apply Thresholds (Get Binary Preds) -> Evaluation (All using train-test sets).\n",
        "\n",
        "This process is a relatively fast process, and it gets good results, using a minimal optimization. I do recommend using the Optuna based process, as it will attempt to find the best model possible for the classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG_hiKpSFJ4c"
      },
      "outputs": [],
      "source": [
        "def FindOptimalThreshold(y_true, y_probs, metric, border_thresh_for_scan = (0.1, 1)):\n",
        "  \"\"\"\n",
        "  Find the optimal threshold to maximize the given metric.\n",
        "\n",
        "  Parameters:\n",
        "  y_true (array-like): True labels.\n",
        "  y_probs (array-like): Predicted probabilities.\n",
        "  metric (str): Metric to maximize ('precision', 'accuracy', 'f1').\n",
        "\n",
        "  Returns:\n",
        "  float: Optimal threshold.\n",
        "  \"\"\"\n",
        "  best_threshold = 0.5\n",
        "  best_score = 0\n",
        "\n",
        "  min_thresh, max_thresh = border_thresh_for_scan\n",
        "  thresholds = np.arange(min_thresh, max_thresh, 0.01)\n",
        "  for threshold in thresholds:\n",
        "      y_pred = (y_probs >= threshold).astype(int)\n",
        "      if metric == 'precision':\n",
        "          score = precision_score(y_true, y_pred)\n",
        "      elif metric == 'accuracy':\n",
        "          score = accuracy_score(y_true, y_pred)\n",
        "      elif metric == 'f1':\n",
        "          score = f1_score(y_true, y_pred)\n",
        "      else:\n",
        "          raise ValueError(\"Unsupported metric: choose from 'precision', 'accuracy', 'f1'\")\n",
        "\n",
        "      if score > best_score:\n",
        "          best_score = score\n",
        "          best_threshold = threshold\n",
        "\n",
        "  return best_threshold\n",
        "\n",
        "\n",
        "\n",
        "def TrainModels(theme_datasets, text_column='Processed Text', metric='precision', min_quality_thresh = 0.5, data_size_thresh = 30):\n",
        "  \"\"\"\n",
        "  Train multiple models for each theme, evaluate their performance, and find optimal thresholds.\n",
        "\n",
        "  Parameters:\n",
        "  theme_datasets (dict): Dictionary containing training and testing sets for each theme.\n",
        "  text_column (str): The column containing the text data.\n",
        "  metric (str): Metric to maximize ('precision', 'accuracy', 'f1').\n",
        "  min_quality_thresh (float): The minimum acceptable classification score by the model, to keep as a valid model.\n",
        "  data_size_thresh (int): Min number of positive samples in the train to deem this model sufficient.\n",
        "\n",
        "  Returns:\n",
        "  dict: Dictionary containing the best models, classification reports, optimal thresholds, and vectorizer.\n",
        "  \"\"\"\n",
        "  results = {}\n",
        "\n",
        "  # Fit the TF-IDF vectorizer on the entire training dataset\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  all_train_texts = pd.concat([datasets['train'][text_column] for datasets in theme_datasets.values()]).drop_duplicates()\n",
        "  vectorizer.fit(all_train_texts)\n",
        "\n",
        "  # Define the models to evaluate\n",
        "  base_models = [\n",
        "      ('SVM', SVC(probability=True, random_state=42)),\n",
        "      ('RandomForest', RandomForestClassifier(random_state=42)),\n",
        "      ('AdaBoost', AdaBoostClassifier(random_state=42))\n",
        "  ]\n",
        "\n",
        "  for theme, datasets in theme_datasets.items():\n",
        "      print(f\"\\n[Runtime Status]: Training for theme {theme}\")\n",
        "      train_worthy = True\n",
        "      train_df = datasets['train']\n",
        "      test_df = datasets['test']\n",
        "      full_ds = datasets['full_ds']\n",
        "\n",
        "      best_model = None\n",
        "      best_threshold = min_quality_thresh\n",
        "      best_score = 0\n",
        "      best_model_name = None\n",
        "      best_conf_mat_test = None\n",
        "      best_conf_mat_train = None\n",
        "      best_conf_mat_full = None\n",
        "\n",
        "      if len(train_df[train_df[theme] == 1]) <= data_size_thresh:\n",
        "        train_worthy = False\n",
        "\n",
        "      if train_worthy:\n",
        "        X_train = vectorizer.transform(train_df[text_column])\n",
        "        X_test = vectorizer.transform(test_df[text_column])\n",
        "        X_full = vectorizer.transform(full_ds[text_column])\n",
        "\n",
        "        for model_name, base_model in base_models:\n",
        "\n",
        "            # Train the model\n",
        "            model = deepcopy(base_model)\n",
        "            model.fit(X_train, train_df[theme])\n",
        "\n",
        "            # Find optimal thresh based on train & Predict probabilities (Train)\n",
        "            train_proba = model.predict_proba(X_train)[:, 1]\n",
        "            optimal_threshold = FindOptimalThreshold(train_df[theme], train_proba, metric)\n",
        "            train_pred = (train_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "            # Predict probabilities (Test)\n",
        "            test_proba = model.predict_proba(X_test)[:, 1]\n",
        "            test_pred = (test_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "            # Predict probabilities (Full DS)\n",
        "            full_data_proba = model.predict_proba(X_full)[:, 1]\n",
        "            full_data_pred = (full_data_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "            # Calculate the score for the current model\n",
        "            if metric == 'precision':\n",
        "                score = precision_score(test_df[theme], test_pred)\n",
        "            elif metric == 'accuracy':\n",
        "                score = accuracy_score(test_df[theme], test_pred)\n",
        "            elif metric == 'f1':\n",
        "                score = f1_score(test_df[theme], test_pred)\n",
        "\n",
        "            # Select the best model based on the score, increase thresh if possible\n",
        "            if score >= best_score:\n",
        "                best_model = model\n",
        "                best_threshold = optimal_threshold\n",
        "                best_score = score\n",
        "                best_model_name = model_name\n",
        "                tn, fp, fn, tp = confusion_matrix(test_df[theme], test_pred).ravel()\n",
        "                best_conf_mat_test = {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn}\n",
        "                tn, fp, fn, tp = confusion_matrix(train_df[theme], train_pred).ravel()\n",
        "                best_conf_mat_train = {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn}\n",
        "                tn, fp, fn, tp = confusion_matrix(full_ds[theme], full_data_pred).ravel()\n",
        "                best_conf_mat_full = {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn}\n",
        "\n",
        "      print(f\"[Runtime Status]: Best model was {best_model_name}, with thresh: {best_threshold}\")\n",
        "      print(f\"[Runtime Status]: Best model's score in the metric is {round(best_score,3)}\")\n",
        "\n",
        "      if best_conf_mat_test:\n",
        "        print(f\"[Runtime Status]: Confusion matrix test: {best_conf_mat_test}\")\n",
        "        print(f\"[Runtime Status]: Confusion matrix train: {best_conf_mat_train}\")\n",
        "        print(f\"[Runtime Status]: Confusion matrix full tagged dataset: {best_conf_mat_full}\")\n",
        "\n",
        "      # Store the best model, report, and optimal threshold\n",
        "      results[theme] = {\n",
        "          'model': best_model,\n",
        "          'optimal_threshold': best_threshold,\n",
        "          'confusion_matrix_test': best_conf_mat_test,\n",
        "          'confusion_matrix_train': best_conf_mat_train,\n",
        "          'confusion_matrix_full': best_conf_mat_full,\n",
        "      }\n",
        "\n",
        "  results['vectorizer'] = vectorizer\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2kXlkxLIcSd",
        "outputId": "8a5301a0-42d0-4b2f-fef0-0c38985ba3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Runtime Status]: Training for theme growth / career development\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.9099999999999996\n",
            "[Runtime Status]: Best model's score in the metric is 1.0\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 5, 'FP': 0, 'FN': 16, 'TN': 242}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 80, 'FP': 0, 'FN': 0, 'TN': 965}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 85, 'FP': 0, 'FN': 16, 'TN': 1207}\n",
            "\n",
            "[Runtime Status]: Training for theme office environment\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.6899999999999997\n",
            "[Runtime Status]: Best model's score in the metric is 0.943\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 33, 'FP': 2, 'FN': 15, 'TN': 212}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 192, 'FP': 0, 'FN': 0, 'TN': 854}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 225, 'FP': 2, 'FN': 15, 'TN': 1066}\n",
            "\n",
            "[Runtime Status]: Training for theme hr\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme communication\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.6599999999999997\n",
            "[Runtime Status]: Best model's score in the metric is 0.929\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 13, 'FP': 1, 'FN': 9, 'TN': 239}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 87, 'FP': 0, 'FN': 0, 'TN': 959}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 100, 'FP': 1, 'FN': 9, 'TN': 1198}\n",
            "\n",
            "[Runtime Status]: Training for theme benefits\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme systems\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.7099999999999996\n",
            "[Runtime Status]: Best model's score in the metric is 0.846\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 22, 'FP': 4, 'FN': 16, 'TN': 220}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 149, 'FP': 0, 'FN': 2, 'TN': 895}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 171, 'FP': 4, 'FN': 18, 'TN': 1115}\n",
            "\n",
            "[Runtime Status]: Training for theme social activities / events\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme management\n",
            "[Runtime Status]: Best model was AdaBoost, with thresh: 0.4999999999999998\n",
            "[Runtime Status]: Best model's score in the metric is 0.7\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 7, 'FP': 3, 'FN': 9, 'TN': 244}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 55, 'FP': 0, 'FN': 6, 'TN': 984}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 62, 'FP': 3, 'FN': 15, 'TN': 1228}\n",
            "\n",
            "[Runtime Status]: Training for theme flexibility\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.7799999999999997\n",
            "[Runtime Status]: Best model's score in the metric is 0.933\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 14, 'FP': 1, 'FN': 9, 'TN': 238}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 90, 'FP': 0, 'FN': 1, 'TN': 955}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 104, 'FP': 1, 'FN': 10, 'TN': 1193}\n",
            "\n",
            "[Runtime Status]: Training for theme employee care and listening\n",
            "[Runtime Status]: Best model was AdaBoost, with thresh: 0.5099999999999998\n",
            "[Runtime Status]: Best model's score in the metric is 0.333\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 1, 'FP': 2, 'FN': 10, 'TN': 249}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 18, 'FP': 0, 'FN': 25, 'TN': 1003}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 19, 'FP': 2, 'FN': 35, 'TN': 1252}\n",
            "\n",
            "[Runtime Status]: Training for theme cross-functional collaboration\n",
            "[Runtime Status]: Best model was RandomForest, with thresh: 0.16999999999999998\n",
            "[Runtime Status]: Best model's score in the metric is 0.5\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 5, 'FP': 5, 'FN': 6, 'TN': 246}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 42, 'FP': 0, 'FN': 0, 'TN': 1004}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 47, 'FP': 5, 'FN': 6, 'TN': 1250}\n",
            "\n",
            "[Runtime Status]: Training for theme within team collaboration\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.1\n",
            "[Runtime Status]: Best model's score in the metric is 0.421\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 8, 'FP': 11, 'FN': 2, 'TN': 241}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 39, 'FP': 0, 'FN': 0, 'TN': 1007}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 47, 'FP': 11, 'FN': 2, 'TN': 1248}\n",
            "\n",
            "[Runtime Status]: Training for theme customer service\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme company\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme salary / compensation\n",
            "[Runtime Status]: Best model was RandomForest, with thresh: 0.2899999999999999\n",
            "[Runtime Status]: Best model's score in the metric is 1.0\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 11, 'FP': 0, 'FN': 3, 'TN': 249}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 53, 'FP': 0, 'FN': 0, 'TN': 992}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 64, 'FP': 0, 'FN': 3, 'TN': 1241}\n",
            "\n",
            "[Runtime Status]: Training for theme recognition\n",
            "[Runtime Status]: Best model was RandomForest, with thresh: 0.2599999999999999\n",
            "[Runtime Status]: Best model's score in the metric is 1.0\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 6, 'FP': 0, 'FN': 8, 'TN': 249}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 53, 'FP': 0, 'FN': 0, 'TN': 992}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 59, 'FP': 0, 'FN': 8, 'TN': 1241}\n",
            "\n",
            "[Runtime Status]: Training for theme training\n",
            "[Runtime Status]: Best model was AdaBoost, with thresh: 0.5099999999999998\n",
            "[Runtime Status]: Best model's score in the metric is 0.96\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 24, 'FP': 1, 'FN': 17, 'TN': 221}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 107, 'FP': 0, 'FN': 53, 'TN': 885}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 131, 'FP': 1, 'FN': 70, 'TN': 1106}\n",
            "\n",
            "[Runtime Status]: Training for theme fairness / equality / inclusion\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme overall engaged/satisfied\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme work process\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme sick / vacation days\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme performance management\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme stability\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme work processes\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme innovation\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme professionalism\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n",
            "\n",
            "[Runtime Status]: Training for theme workload / work-life balance\n",
            "[Runtime Status]: Best model was SVM, with thresh: 0.2699999999999999\n",
            "[Runtime Status]: Best model's score in the metric is 0.65\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 13, 'FP': 7, 'FN': 12, 'TN': 230}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 100, 'FP': 0, 'FN': 0, 'TN': 946}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 113, 'FP': 7, 'FN': 12, 'TN': 1176}\n",
            "\n",
            "[Runtime Status]: Training for theme company culture\n",
            "[Runtime Status]: Best model was AdaBoost, with thresh: 0.4999999999999998\n",
            "[Runtime Status]: Best model's score in the metric is 0.647\n",
            "[Runtime Status]: Confusion matrix test: {'TP': 11, 'FP': 6, 'FN': 8, 'TN': 237}\n",
            "[Runtime Status]: Confusion matrix train: {'TP': 65, 'FP': 0, 'FN': 10, 'TN': 971}\n",
            "[Runtime Status]: Confusion matrix full tagged dataset: {'TP': 76, 'FP': 6, 'FN': 18, 'TN': 1208}\n",
            "\n",
            "[Runtime Status]: Training for theme challenging work\n",
            "[Runtime Status]: Best model was None, with thresh: 0.5\n",
            "[Runtime Status]: Best model's score in the metric is 0\n"
          ]
        }
      ],
      "source": [
        "training_results = TrainModels(theme_datasets, metric='precision')\n",
        "with open('ThemeClassifierModels.pkl', 'wb') as f:\n",
        "    pickle.dump(training_results, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4B9JL_iSZ22"
      },
      "source": [
        "## Optimal Training using Optuna\n",
        "\n",
        "This is an enhanced training process, aimed at creating the most accurate model for each theme. This process is a lot more expensive computationally, and should be considered as such.\n",
        "\n",
        "For each theme, an optimization flow will take place, in which it will attamt to optimize it's hyperparameters for stable yet great results. After each model type it trained to it's best result, the best model will be chosen -> The model for which the best threshold yields the best results in the cross validation. This will be the final model chosen.\n",
        "\n",
        "NOTES:  \n",
        "\n",
        "*   Using ThreadPool might speedup the process, but might also mess the log prints at the current version. For me it's not important enough, but feel free to explore.\n",
        "*   This training process is built on very small training set, so the models experimented with are relatively simple models.\n",
        "* Given the nature of the problem as a multi-class multi-label problem, I chose to maximize the Percision score per class, while allowing the model to improve in recall, if reached percision = 100%. For computation considerations, I chose to stop training with a simple model, if the model reached percision >= 90% and recall >= 50%. This of course is flexible.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6BfBtoDUN7Iz"
      },
      "outputs": [],
      "source": [
        "# Set up logging to minimize Optuna's output verbosity\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# Hyperparameter search space for different models\n",
        "model_hyperparameters = {\n",
        "    'LogisticRegression': {\n",
        "        'C': (1e-4, 1e2, 'loguniform'),\n",
        "        'penalty': (['l2'], 'categorical'),\n",
        "        'fit_intercept': ([True, False], 'categorical'),\n",
        "    },\n",
        "    'SVM': {\n",
        "        'C': (1e-4, 1e2, 'loguniform'),\n",
        "        'kernel': (['linear', 'poly', 'rbf', 'sigmoid'], 'categorical'),\n",
        "        'degree': (2, 5, 'int'),  # Only relevant for 'poly' kernel\n",
        "        'gamma': (['scale', 'auto'], 'categorical'),\n",
        "        'coef0': (-1, 1, 'uniform'),  # Used for 'poly' and 'sigmoid'\n",
        "    },\n",
        "    'RandomForest': {\n",
        "        'n_estimators': (50, 200, 'int'),\n",
        "        'max_depth': (5, 30, 'int'),\n",
        "        'min_samples_split': (2, 10, 'int'),\n",
        "        'min_samples_leaf': (1, 5, 'int'),\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': (50, 200, 'int'),\n",
        "        'learning_rate': (0.01, 1.0, 'loguniform'),\n",
        "    }\n",
        "}\n",
        "\n",
        "def _suggest_hyperparameters(trial, hyperparams):\n",
        "    \"\"\"\n",
        "    Suggest hyperparameters for a model using the Optuna trial object.\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "    for key, value in hyperparams.items():\n",
        "        if len(value) == 2 and value[1] == 'categorical':\n",
        "            params[key] = trial.suggest_categorical(key, value[0])\n",
        "        elif len(value) == 3:\n",
        "            if value[2] == 'loguniform':\n",
        "                params[key] = trial.suggest_float(key, value[0], value[1], log=True)\n",
        "            elif value[2] == 'uniform':\n",
        "                params[key] = trial.suggest_float(key, value[0], value[1])\n",
        "            elif value[2] == 'int':\n",
        "                params[key] = trial.suggest_int(key, value[0], value[1])\n",
        "            elif value[2] == 'categorical':\n",
        "                params[key] = trial.suggest_categorical(key, value[0])\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown value format for hyperparameter {key}: {value}\")\n",
        "    return params\n",
        "\n",
        "def _find_optimal_threshold(y_true, y_probs, scoring_metric):\n",
        "    \"\"\"\n",
        "    Find the optimal threshold using Bayesian optimization to maximize the given metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def objective(threshold):\n",
        "        y_pred = (y_probs >= threshold).astype(int)\n",
        "        return -scoring_metric(y_true, y_pred)\n",
        "\n",
        "    result = gp_minimize(objective, [(0.1, 1.0)], n_calls=20)\n",
        "\n",
        "    return result.x[0]  # The best threshold found\n",
        "\n",
        "\n",
        "def _objective(trial, model, model_name, X_full, y_full, model_hyperparameters, scoring_metric):\n",
        "    \"\"\"\n",
        "    Objective function for Optuna to optimize based on both model parameters and threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get hyperparameters for the model\n",
        "    hyperparams = model_hyperparameters[model_name]\n",
        "    params = _suggest_hyperparameters(trial, hyperparams)\n",
        "\n",
        "    # Set model parameters\n",
        "    model.set_params(**params)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_full, y_full)\n",
        "\n",
        "    # Predict probabilities\n",
        "    y_probs = model.predict_proba(X_full)[:, 1]\n",
        "\n",
        "    # Find the best threshold for this set of hyperparameters\n",
        "    best_threshold = _find_optimal_threshold(y_full, y_probs, scoring_metric)\n",
        "\n",
        "    # Convert probabilities to binary predictions based on the best threshold\n",
        "    y_pred = (y_probs >= best_threshold).astype(int)\n",
        "\n",
        "    # Evaluate the model with the chosen threshold\n",
        "    score = scoring_metric(y_full, y_pred)\n",
        "\n",
        "    # Log the threshold and score for tracking\n",
        "    trial.set_user_attr(\"threshold\", best_threshold)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def _optimize_model_with_optuna(model, model_name, X_full, y_full, model_hyperparameters, scoring_metric, n_trials=100, timeout=1200):\n",
        "    \"\"\"\n",
        "    Optimize a machine learning model using Optuna for hyperparameter and threshold tuning.\n",
        "    \"\"\"\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "\n",
        "    print(f\"--> [Model Selection Status]: Starting Optuna optimization for {model_name} with {n_trials} trials.\")\n",
        "\n",
        "    # Optimize both hyperparameters and the threshold\n",
        "    study.optimize(lambda trial: _objective(trial, model, model_name, X_full, y_full, model_hyperparameters, scoring_metric),\n",
        "                   n_trials=n_trials, timeout=timeout)\n",
        "\n",
        "    # Retrieve the best parameters and threshold from the study\n",
        "    best_params = study.best_params\n",
        "    best_value = study.best_value\n",
        "    best_threshold = study.best_trial.user_attrs[\"threshold\"]\n",
        "\n",
        "    print(f\"--> [Model Selection Status]: Finished Optuna optimization for {model_name}. Best metric score: {best_value}, Best threshold: {best_threshold}\")\n",
        "\n",
        "    return best_params, best_threshold, best_value\n",
        "\n",
        "\n",
        "def TrainModelsWithOptuna(theme_datasets, text_column='Processed Text', metric=precision_score, min_quality_thresh=0.5,\n",
        "                          sufficient_quality_thresh=0.9, sufficient_recall_thresh=0.5, data_size_thresh=30, n_trials=50, timeout=180):\n",
        "    \"\"\"\n",
        "    Train models for each theme using Optuna to find the best hyperparameters and threshold.\n",
        "\n",
        "    Args:\n",
        "    - theme_datasets (dict): Datasets for each theme, with text and labels.\n",
        "    - text_column (str): The column containing the processed text. Default is 'Processed Text'.\n",
        "    - metric (callable): Metric to optimize (e.g., f1_score). Default is F1.\n",
        "    - min_quality_thresh (float): Minimum acceptable score to keep the model. Default is 0.5.\n",
        "    - sufficient_quality_thresh (float): Score where there is no need to test additional models types (refrain from relying on heavy models). Default is 0.9.\n",
        "    - sufficient_recall_thresh (float): Ratio of TP/(TP+FN) for stopping early. Default is 0.5.\n",
        "    - data_size_thresh (int): Minimum number of samples required to train a model. Default is 30.\n",
        "    - n_trials (int): Number of Optuna trials to run. Default is 50.\n",
        "    - timeout (int): Maximum time (seconds) to spend on optimization per theme. Default is 180.\n",
        "\n",
        "    Returns:\n",
        "    - results (dict): Best model, hyperparameters, threshold, and performance for each theme.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Fit the TF-IDF vectorizer on the entire training dataset\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    all_train_texts = pd.concat([datasets['train'][text_column] for datasets in theme_datasets.values()]).drop_duplicates()\n",
        "    vectorizer.fit(all_train_texts)\n",
        "\n",
        "    # Define the models to evaluate with Optuna\n",
        "    candidate_models = {\n",
        "        'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'SVM': SVC(probability=True, random_state=42),\n",
        "        'RandomForest': RandomForestClassifier(random_state=42),\n",
        "        'AdaBoost': AdaBoostClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    for theme, datasets in theme_datasets.items():\n",
        "        print(f\"\\n[Runtime Status]: Starting training for theme: {theme}\")\n",
        "\n",
        "        train_df = datasets['train']\n",
        "        full_ds = datasets['full_ds']\n",
        "\n",
        "        best_model = None\n",
        "        best_threshold = 0\n",
        "        best_score = min_quality_thresh\n",
        "        best_model_recall = 0\n",
        "        best_model_name = None\n",
        "        best_conf_mat_full = None\n",
        "\n",
        "        if len(train_df[train_df[theme] == 1]) <= data_size_thresh:\n",
        "            print(f\"[Runtime Status]: Skipping theme {theme} due to insufficient positive samples (less than {data_size_thresh} positive records).\")\n",
        "            continue\n",
        "\n",
        "        X_full = vectorizer.transform(full_ds[text_column])\n",
        "        y_full = full_ds[theme]\n",
        "\n",
        "        for model_name, base_model in candidate_models.items():\n",
        "            print(f\"[Runtime Status]: Optimizing model {model_name} for theme {theme}\")\n",
        "\n",
        "            model_copy = deepcopy(base_model)\n",
        "\n",
        "            # Optimize model with Optuna (both hyperparameters and threshold)\n",
        "            best_params, best_optuna_threshold, model_optuna_score = _optimize_model_with_optuna(\n",
        "                model_copy, model_name, X_full, y_full, model_hyperparameters, metric, n_trials=n_trials, timeout=timeout\n",
        "            )\n",
        "\n",
        "            if model_optuna_score >= best_score:\n",
        "              # Train the model with the best parameters\n",
        "              optimized_model = model_copy.set_params(**best_params)\n",
        "              optimized_model.fit(X_full, y_full)\n",
        "\n",
        "              # Predict probabilities (Full DS)\n",
        "              full_data_proba = optimized_model.predict_proba(X_full)[:, 1]\n",
        "              full_data_pred = (full_data_proba >= best_optuna_threshold).astype(int)\n",
        "\n",
        "              # Calculate recall for the optimised model\n",
        "              total_model_recall_score = recall_score(y_full, full_data_pred) # For stopping criteria\n",
        "\n",
        "              # Select the best model based on the score (CV Optuna), while allowing model's with similar score but higher recall to be picked\n",
        "              if (model_optuna_score > best_score) or (total_model_recall_score > best_model_recall):\n",
        "                best_model = optimized_model\n",
        "                best_threshold = best_optuna_threshold\n",
        "                best_score = model_optuna_score\n",
        "                best_model_recall = total_model_recall_score\n",
        "                best_model_name = model_name\n",
        "                tn, fp, fn, tp = confusion_matrix(y_full, full_data_pred).ravel()\n",
        "                best_conf_mat_full = {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn}\n",
        "\n",
        "                # Early stop for the optimization process if a good enough result found:\n",
        "                if best_score >= sufficient_quality_thresh and total_model_recall_score > sufficient_recall_thresh:\n",
        "                  print('[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme')\n",
        "                  break  # Stop further model evaluation\n",
        "\n",
        "        if not best_model_name:\n",
        "          print(f\"[Runtime Status]: Finished training for theme {theme}, but no model achieved sufficient results. No instance will be saved.\")\n",
        "        else:\n",
        "          # After the loop ends (whether early stopped or not), store the final model and its results\n",
        "          print(f\"[Runtime Status]: Finished training for theme {theme}. Chose model: {best_model_name}\")\n",
        "          print(f\"[Runtime Status]: Best model score on full data set: {round(best_score, 3)}, Recall={best_model_recall}\")\n",
        "          print(f\"[Runtime Status]: Optimal threshold: {best_threshold}\")\n",
        "\n",
        "          if best_conf_mat_full:\n",
        "              print(f\"--> [Runtime Status]: Confusion matrix full tagged dataset: {best_conf_mat_full}\")\n",
        "\n",
        "          # Store the best model, report, and optimal threshold for the theme\n",
        "          best_model_instance = deepcopy(best_model)\n",
        "          results[theme] = {\n",
        "              'model': deepcopy(best_model),\n",
        "              'optimal_threshold': deepcopy(best_threshold),\n",
        "              'confusion_matrix_full': deepcopy(best_conf_mat_full)\n",
        "          }\n",
        "    results['vectorizer'] = vectorizer\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0l4_cVEPrJb",
        "outputId": "55089bb5-69f3-4200-dc74-4a81d1dd5182"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Runtime Status]: Starting training for theme: innovation\n",
            "[Runtime Status]: Skipping theme innovation due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: stability\n",
            "[Runtime Status]: Skipping theme stability due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: hr\n",
            "[Runtime Status]: Skipping theme hr due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: company culture\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme company culture\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.592859049685727\n",
            "[Runtime Status]: Optimizing model SVM for theme company culture\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.7060268076594005\n",
            "[Runtime Status]: Optimizing model RandomForest for theme company culture\n",
            "--> [Model Selection Status]: Starting Optuna optimization for RandomForest with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for RandomForest. Best metric score: 1.0, Best threshold: 0.3308202536918813\n",
            "[Runtime Status]: Optimizing model AdaBoost for theme company culture\n",
            "--> [Model Selection Status]: Starting Optuna optimization for AdaBoost with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for AdaBoost. Best metric score: 1.0, Best threshold: 0.5269300506872284\n",
            "[Runtime Status]: Finished training for theme company culture. Chose model: AdaBoost\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.19148936170212766\n",
            "[Runtime Status]: Optimal threshold: 0.5269300506872284\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 18, 'FP': 0, 'FN': 76, 'TN': 1214}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: overall engaged/satisfied\n",
            "[Runtime Status]: Skipping theme overall engaged/satisfied due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: fairness / equality / inclusion\n",
            "[Runtime Status]: Skipping theme fairness / equality / inclusion due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: work processes\n",
            "[Runtime Status]: Skipping theme work processes due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: challenging work\n",
            "[Runtime Status]: Skipping theme challenging work due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: cross-functional collaboration\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme cross-functional collaboration\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.5053397861417758]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7774521000139742]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.745396592017376\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme cross-functional collaboration. Chose model: LogisticRegression\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.745396592017376\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 53, 'FP': 0, 'FN': 0, 'TN': 1255}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: within team collaboration\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme within team collaboration\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.6977615938777294\n",
            "[Runtime Status]: Optimizing model SVM for theme within team collaboration\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.4564752205405479\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme within team collaboration. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.8775510204081632\n",
            "[Runtime Status]: Optimal threshold: 0.4564752205405479\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 43, 'FP': 0, 'FN': 6, 'TN': 1259}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: recognition\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme recognition\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.5581474688402699]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.6629272283320496\n",
            "[Runtime Status]: Optimizing model SVM for theme recognition\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.7508685633395493\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme recognition. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.7508685633395493\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 67, 'FP': 0, 'FN': 0, 'TN': 1241}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: flexibility\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme flexibility\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.10422267518938347\n",
            "[Runtime Status]: Optimizing model SVM for theme flexibility\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.7565140856534859\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme flexibility. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.9912280701754386\n",
            "[Runtime Status]: Optimal threshold: 0.7565140856534859\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 113, 'FP': 0, 'FN': 1, 'TN': 1194}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: salary / compensation\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme salary / compensation\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9337711446815308]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.5042268189708289\n",
            "[Runtime Status]: Optimizing model SVM for theme salary / compensation\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9228238858324352]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.12706501186849856]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.4476002309538962]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.4435868362325799]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.9258108497145747\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme salary / compensation. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.5373134328358209\n",
            "[Runtime Status]: Optimal threshold: 0.9258108497145747\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 36, 'FP': 0, 'FN': 31, 'TN': 1241}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: workload / work-life balance\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme workload / work-life balance\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.4528172981536397]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.46949133366771867]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.4577921024175413]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.16592991105085184]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9776104324234222]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.6654694810384542]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.5164249377073273\n",
            "[Runtime Status]: Optimizing model SVM for theme workload / work-life balance\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.5493207392090165\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme workload / work-life balance. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.5493207392090165\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 125, 'FP': 0, 'FN': 0, 'TN': 1183}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: sick / vacation days\n",
            "[Runtime Status]: Skipping theme sick / vacation days due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: social activities / events\n",
            "[Runtime Status]: Skipping theme social activities / events due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: systems\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme systems\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.5836262375758494\n",
            "[Runtime Status]: Optimizing model SVM for theme systems\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.816848864854071\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme systems. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.816848864854071\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 189, 'FP': 0, 'FN': 0, 'TN': 1119}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: benefits\n",
            "[Runtime Status]: Skipping theme benefits due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: training\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme training\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.9678183236885217\n",
            "[Runtime Status]: Optimizing model SVM for theme training\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.4671246261495925\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme training. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.4671246261495925\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 201, 'FP': 0, 'FN': 0, 'TN': 1107}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: management\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme management\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.48991884644231887]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9181440266437118]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.8473166493428916]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7198842218876597]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7558357932907844]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.499160795368364]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.1248998240918716]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.628110377390067]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.8185447707916212]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7765908519283828]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.10294390069976067]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.154622618296067]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9861226669631407]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.2485250921319261]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.5980044729954431]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.5430691805586467\n",
            "[Runtime Status]: Optimizing model SVM for theme management\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.8462131984953278\n",
            "[Runtime Status]: Optimizing model RandomForest for theme management\n",
            "--> [Model Selection Status]: Starting Optuna optimization for RandomForest with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for RandomForest. Best metric score: 1.0, Best threshold: 0.362925453128371\n",
            "[Runtime Status]: Optimizing model AdaBoost for theme management\n",
            "--> [Model Selection Status]: Starting Optuna optimization for AdaBoost with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for AdaBoost. Best metric score: 1.0, Best threshold: 0.6379002915523491\n",
            "[Runtime Status]: Finished training for theme management. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.2597402597402597\n",
            "[Runtime Status]: Optimal threshold: 0.8462131984953278\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 20, 'FP': 0, 'FN': 57, 'TN': 1231}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: performance management\n",
            "[Runtime Status]: Skipping theme performance management due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: communication\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme communication\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.12268622313437623]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.43289524423219417]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.6362798908792409]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.891083253413765]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.394726312022845]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.35490074722473985]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.2755485281991016]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7201392516708073]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7091309274650005]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9767642089457296]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.6133188665846248\n",
            "[Runtime Status]: Optimizing model SVM for theme communication\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.8888735541044995\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme communication. Chose model: SVM\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=1.0\n",
            "[Runtime Status]: Optimal threshold: 0.8888735541044995\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 109, 'FP': 0, 'FN': 0, 'TN': 1199}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: office environment\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme office environment\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.6492340018963099\n",
            "[Runtime Status]: Optimizing model SVM for theme office environment\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.9921744566931276\n",
            "[Runtime Status]: Optimizing model RandomForest for theme office environment\n",
            "--> [Model Selection Status]: Starting Optuna optimization for RandomForest with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for RandomForest. Best metric score: 1.0, Best threshold: 0.43214085717323125\n",
            "[Runtime Status]: Optimizing model AdaBoost for theme office environment\n",
            "--> [Model Selection Status]: Starting Optuna optimization for AdaBoost with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for AdaBoost. Best metric score: 1.0, Best threshold: 0.6189114600921513\n",
            "[Runtime Status]: Finished training for theme office environment. Chose model: RandomForest\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.3\n",
            "[Runtime Status]: Optimal threshold: 0.43214085717323125\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 72, 'FP': 0, 'FN': 168, 'TN': 1068}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: customer service\n",
            "[Runtime Status]: Skipping theme customer service due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: company\n",
            "[Runtime Status]: Skipping theme company due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: growth / career development\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme growth / career development\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.769258709724963\n",
            "[Runtime Status]: Model score exceeded the required threshold, stopping training for this theme\n",
            "[Runtime Status]: Finished training for theme growth / career development. Chose model: LogisticRegression\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.5148514851485149\n",
            "[Runtime Status]: Optimal threshold: 0.769258709724963\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 52, 'FP': 0, 'FN': 49, 'TN': 1207}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: employee care and listening\n",
            "[Runtime Status]: Optimizing model LogisticRegression for theme employee care and listening\n",
            "--> [Model Selection Status]: Starting Optuna optimization for LogisticRegression with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for LogisticRegression. Best metric score: 1.0, Best threshold: 0.5017424575670637\n",
            "[Runtime Status]: Optimizing model SVM for theme employee care and listening\n",
            "--> [Model Selection Status]: Starting Optuna optimization for SVM with 50 trials.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.3642116626935884]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.1207724185909495]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9539070233212451]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9982543823484281]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.724725996305966]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9545852267865912]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.3761591377507686]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.3191485358282705]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.30949439852483396]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7682027505760941]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.6060258040967197]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.5481476304007483]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.22916445162715796]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for SVM. Best metric score: 1.0, Best threshold: 0.47772624668875396\n",
            "[Runtime Status]: Optimizing model RandomForest for theme employee care and listening\n",
            "--> [Model Selection Status]: Starting Optuna optimization for RandomForest with 50 trials.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.3076524270471821]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.9786082928283681]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.4389383859104351]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7848213074416733]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7152843230546989]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.23638248699775263]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.132871245066013]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.2815235019155699]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1] before, using random point [0.7588907678100297]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [Model Selection Status]: Finished Optuna optimization for RandomForest. Best metric score: 1.0, Best threshold: 0.2628889407738741\n",
            "[Runtime Status]: Optimizing model AdaBoost for theme employee care and listening\n",
            "--> [Model Selection Status]: Starting Optuna optimization for AdaBoost with 50 trials.\n",
            "--> [Model Selection Status]: Finished Optuna optimization for AdaBoost. Best metric score: 1.0, Best threshold: 0.5278951823786457\n",
            "[Runtime Status]: Finished training for theme employee care and listening. Chose model: RandomForest\n",
            "[Runtime Status]: Best model score on full data set: 1.0, Recall=0.18518518518518517\n",
            "[Runtime Status]: Optimal threshold: 0.2628889407738741\n",
            "--> [Runtime Status]: Confusion matrix full tagged dataset: {'TP': 10, 'FP': 0, 'FN': 44, 'TN': 1254}\n",
            "\n",
            "[Runtime Status]: Starting training for theme: work process\n",
            "[Runtime Status]: Skipping theme work process due to insufficient positive samples (less than 30 positive records).\n",
            "\n",
            "[Runtime Status]: Starting training for theme: professionalism\n",
            "[Runtime Status]: Skipping theme professionalism due to insufficient positive samples (less than 30 positive records).\n"
          ]
        }
      ],
      "source": [
        "training_results = TrainModelsWithOptuna(theme_datasets)\n",
        "with open('ThemeClassifierModels.pkl', 'wb') as f:\n",
        "    pickle.dump(training_results, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwDgxVdjP0Zr"
      },
      "source": [
        "### Total preformance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DektjoP0-cC5"
      },
      "outputs": [],
      "source": [
        "def Evaluate(tagged_data, results, text_column='Processed Text'):\n",
        "    \"\"\"\n",
        "    Evaluate all themes using the trained models and calculate classification reports.\n",
        "\n",
        "    Parameters:\n",
        "    tagged_data (pd.DataFrame): The input DataFrame.\n",
        "    results (dict): Dictionary containing the best models, classification reports, optimal thresholds, and vectorizer.\n",
        "    text_column (str): The column containing the text data.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame containing detailed metrics and averages for each theme.\n",
        "    \"\"\"\n",
        "    metrics = []\n",
        "    tagged_data_b = _BinaryThemeColumns(tagged_data, themes_column='Themes')\n",
        "    vectorizer = results['vectorizer']\n",
        "    X = vectorizer.transform(tagged_data_b[text_column])\n",
        "    for theme, model_packet in results.items():\n",
        "        if theme == 'vectorizer':\n",
        "            continue\n",
        "\n",
        "        y_true = tagged_data_b[theme].copy()\n",
        "        model = model_packet['model']\n",
        "        optimal_threshold = model_packet['optimal_threshold']\n",
        "\n",
        "        if model is None:\n",
        "            y_pred = np.zeros(len(tagged_data_b), dtype=int)\n",
        "        else:\n",
        "            # Predict theme for all samples\n",
        "            y_probs = model.predict_proba(X)[:, 1]\n",
        "            y_pred = (y_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "        # Calculate confusion matrix and metrics\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        precision = round(precision_score(y_true, y_pred, zero_division=0), 3)\n",
        "        recall = round(recall_score(y_true, y_pred, zero_division=0), 3)\n",
        "        accuracy = round(accuracy_score(y_true, y_pred), 3)\n",
        "        f1 = round(f1_score(y_true, y_pred, zero_division=0), 3)\n",
        "        support = sum(y_true)\n",
        "        total_predictions = sum(y_pred)\n",
        "\n",
        "        # Store metrics for the current theme\n",
        "        theme_res = {\n",
        "            'theme': theme,\n",
        "            'TP': tp,\n",
        "            'FP': fp,\n",
        "            'FN': fn,\n",
        "            'TN': tn,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'support': support,\n",
        "            'total predictions': total_predictions\n",
        "        }\n",
        "        metrics.append(theme_res)\n",
        "\n",
        "    # Create DataFrame from metrics\n",
        "    metrics_df = pd.DataFrame(metrics)\n",
        "    metrics_df[['TP', 'FP', 'FN', 'TN']] = metrics_df[['TP', 'FP', 'FN', 'TN']].astype(int)\n",
        "\n",
        "    # Calculate simple averages\n",
        "    simple_avg = metrics_df[['precision', 'recall', 'accuracy', 'f1']].mean().to_dict()\n",
        "    simple_avg['theme'] = 'Simple Average'\n",
        "    simple_avg['support'] = metrics_df['support'].sum().astype(int)\n",
        "    simple_avg['total predictions'] = metrics_df['total predictions'].sum().astype(int)\n",
        "\n",
        "    # Calculate weighted averages\n",
        "    weighted_avg = metrics_df.apply(lambda x: x[['precision', 'recall', 'accuracy', 'f1']] * x['support'], axis=1).sum() / metrics_df['support'].sum()\n",
        "    weighted_avg = weighted_avg.to_dict()\n",
        "    weighted_avg['theme'] = 'Weighted Average'\n",
        "    weighted_avg['total predictions'] = f\"{round(metrics_df['total predictions'].sum().astype(int)/ metrics_df['support'].sum().astype(int),2)*100}%\"\n",
        "\n",
        "    # Append averages to metrics using pd.concat\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame([simple_avg]), pd.DataFrame([weighted_avg])], ignore_index=True)\n",
        "\n",
        "    return metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "djkaYb6aKdmT",
        "outputId": "c1d3393a-66ce-4493-f921-78c1614fed8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             theme     TP   FP     FN      TN  precision  \\\n",
              "0                  company culture   18.0  0.0   76.0  1214.0        1.0   \n",
              "1   cross-functional collaboration   53.0  0.0    0.0  1255.0        1.0   \n",
              "2        within team collaboration   43.0  0.0    6.0  1259.0        1.0   \n",
              "3                      recognition   67.0  0.0    0.0  1241.0        1.0   \n",
              "4                      flexibility  113.0  0.0    1.0  1194.0        1.0   \n",
              "5            salary / compensation   36.0  0.0   31.0  1241.0        1.0   \n",
              "6     workload / work-life balance  125.0  0.0    0.0  1183.0        1.0   \n",
              "7                          systems  189.0  0.0    0.0  1119.0        1.0   \n",
              "8                         training  201.0  0.0    0.0  1107.0        1.0   \n",
              "9                       management   20.0  0.0   57.0  1231.0        1.0   \n",
              "10                   communication  109.0  0.0    0.0  1199.0        1.0   \n",
              "11              office environment   72.0  0.0  168.0  1068.0        1.0   \n",
              "12     growth / career development   52.0  0.0   49.0  1207.0        1.0   \n",
              "13     employee care and listening   10.0  0.0   44.0  1254.0        1.0   \n",
              "14                  Simple Average    NaN  NaN    NaN     NaN        1.0   \n",
              "15                Weighted Average    NaN  NaN    NaN     NaN        1.0   \n",
              "\n",
              "      recall  accuracy        f1  support total predictions  \n",
              "0   0.191000  0.942000  0.321000     94.0                18  \n",
              "1   1.000000  1.000000  1.000000     53.0                53  \n",
              "2   0.878000  0.995000  0.935000     49.0                43  \n",
              "3   1.000000  1.000000  1.000000     67.0                67  \n",
              "4   0.991000  0.999000  0.996000    114.0               113  \n",
              "5   0.537000  0.976000  0.699000     67.0                36  \n",
              "6   1.000000  1.000000  1.000000    125.0               125  \n",
              "7   1.000000  1.000000  1.000000    189.0               189  \n",
              "8   1.000000  1.000000  1.000000    201.0               201  \n",
              "9   0.260000  0.956000  0.412000     77.0                20  \n",
              "10  1.000000  1.000000  1.000000    109.0               109  \n",
              "11  0.300000  0.872000  0.462000    240.0                72  \n",
              "12  0.515000  0.963000  0.680000    101.0                52  \n",
              "13  0.185000  0.966000  0.312000     54.0                10  \n",
              "14  0.704071  0.976357  0.772643   1540.0              1108  \n",
              "15  0.719451  0.969416  0.784739      NaN             72.0%  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13780ea7-e67f-4752-a0d2-b37ee9a8e3a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "      <th>total predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>company culture</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1214.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>0.321000</td>\n",
              "      <td>94.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cross-functional collaboration</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1255.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>53.0</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>within team collaboration</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1259.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.878000</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>49.0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recognition</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>67.0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flexibility</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991000</td>\n",
              "      <td>0.999000</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>114.0</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>salary / compensation</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>0.699000</td>\n",
              "      <td>67.0</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>workload / work-life balance</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>125.0</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>systems</td>\n",
              "      <td>189.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1119.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>189.0</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>training</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>201.0</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>management</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1231.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>77.0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>communication</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1199.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>109.0</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>office environment</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>1068.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.872000</td>\n",
              "      <td>0.462000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>growth / career development</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.963000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>101.0</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>employee care and listening</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1254.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Simple Average</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.704071</td>\n",
              "      <td>0.976357</td>\n",
              "      <td>0.772643</td>\n",
              "      <td>1540.0</td>\n",
              "      <td>1108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Weighted Average</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.719451</td>\n",
              "      <td>0.969416</td>\n",
              "      <td>0.784739</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.0%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13780ea7-e67f-4752-a0d2-b37ee9a8e3a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13780ea7-e67f-4752-a0d2-b37ee9a8e3a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13780ea7-e67f-4752-a0d2-b37ee9a8e3a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c16cce3-94cc-439d-93a3-71cd865088c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c16cce3-94cc-439d-93a3-71cd865088c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c16cce3-94cc-439d-93a3-71cd865088c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"Evaluate(tagged_data, training_results, text_column='Processed Text')\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"theme\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"company culture\",\n          \"cross-functional collaboration\",\n          \"salary / compensation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.67676927515447,\n        \"min\": 10.0,\n        \"max\": 201.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          20.0,\n          72.0,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.43717649993214,\n        \"min\": 0.0,\n        \"max\": 168.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          49.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.060226183646435,\n        \"min\": 1068.0,\n        \"max\": 1259.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1207.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.326093510768125,\n        \"min\": 0.185,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03369509157351361,\n        \"min\": 0.872,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2637264220465453,\n        \"min\": 0.312,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 373.7328432118832,\n        \"min\": 49.0,\n        \"max\": 1540.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          109.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total predictions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "Evaluate(tagged_data, training_results, text_column='Processed Text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h9f2Pz1VSiy"
      },
      "source": [
        "# Predict on New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8P2Z9Jz5VU4k"
      },
      "outputs": [],
      "source": [
        "def Predict(tagged_data, results, text_column='Processed Text'):\n",
        "    \"\"\"\n",
        "    Predict themes for the input DataFrame using the trained models and add a 'Themes' column.\n",
        "\n",
        "    Parameters:\n",
        "    tagged_data (pd.DataFrame): The input DataFrame without theme columns.\n",
        "    results (dict): Dictionary containing the best models, classification reports, optimal thresholds, and vectorizer.\n",
        "    text_column (str): The column containing the text data.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame with an added 'Themes' column containing the predicted themes.\n",
        "    \"\"\"\n",
        "    df = tagged_data.copy()\n",
        "    df = df.reset_index(drop=True)\n",
        "    vectorizer = results['vectorizer']\n",
        "    X = vectorizer.transform(df[text_column])\n",
        "\n",
        "    theme_predictions = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        predicted_themes = []\n",
        "        for theme, model_packet in results.items():\n",
        "            if theme == 'vectorizer':\n",
        "                continue\n",
        "\n",
        "            model = model_packet['model']\n",
        "            optimal_threshold = model_packet['optimal_threshold']\n",
        "\n",
        "            if model is not None:\n",
        "                # Predict probabilities\n",
        "                y_probs = model.predict_proba(X[index])[0, 1]\n",
        "\n",
        "                # Predict label based on optimal threshold\n",
        "                y_pred = (y_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "                if y_pred == 1:\n",
        "                    predicted_themes.append(theme)\n",
        "\n",
        "        theme_predictions.append(\", \".join(predicted_themes))\n",
        "\n",
        "    df['Themes_Predicted'] = theme_predictions\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wOpThb37VX0B"
      },
      "outputs": [],
      "source": [
        "# Input does not have to be tagged, but must have a 'Processed Text' column\n",
        "Predict(tagged_data, training_results, text_column='Processed Text')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0Kw7wvc1SE_8"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}